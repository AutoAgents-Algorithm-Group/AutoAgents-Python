"""
ExecuteNode - ä»»åŠ¡æ‰§è¡ŒèŠ‚ç‚¹
"""

from typing import List, Dict, Any, Optional, Tuple
from langchain_core.messages import HumanMessage, SystemMessage
from loguru import logger


class ExecuteNode:
    """
    ä»»åŠ¡æ‰§è¡ŒèŠ‚ç‚¹
    
    èŒè´£ï¼š
    - é€‰æ‹©å¹¶è°ƒç”¨å·¥å…·
    - æ£€æµ‹ä¿¡æ¯å¢é‡
    - åˆ¤æ–­æ­¥éª¤æ˜¯å¦å®Œæˆ
    """
    
    def __init__(
        self,
        llm: Optional[object] = None,
        min_calls_before_complete: int = 2,
        similarity_threshold: float = 0.9,
        max_total_exec_rounds: int = 20
    ):
        """
        åˆå§‹åŒ–æ‰§è¡ŒèŠ‚ç‚¹
        
        Args:
            llm: ChatClient å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            min_calls_before_complete: æ­¥éª¤å®Œæˆå‰çš„æœ€å°è°ƒç”¨æ¬¡æ•°
            similarity_threshold: ä¿¡æ¯å¢é‡æ£€æµ‹çš„ç›¸ä¼¼åº¦é˜ˆå€¼
            max_total_exec_rounds: æœ€å¤§æ€»æ‰§è¡Œè½®æ¬¡
        """
        self.llm_client = llm
        self.min_calls_before_complete = min_calls_before_complete
        self.similarity_threshold = similarity_threshold
        self.max_total_exec_rounds = max_total_exec_rounds
    
    def __call__(self, state: dict) -> dict:
        """
        æ‰§è¡Œä»»åŠ¡
        
        Args:
            state: AgentState å­—å…¸
            
        Returns:
            æ›´æ–°åçš„ state
        """
        log = logger.bind(category="Execute")
        log.info(f"ğŸ”§ è¿›å…¥æ‰§è¡ŒèŠ‚ç‚¹ (æ‰§è¡Œè½®æ¬¡: {state['execution_rounds'] + 1}/{self.max_total_exec_rounds})")
        
        if state['execution_rounds'] >= 40 or state['abort_flag']:  # ä½¿ç”¨é»˜è®¤å€¼
            log.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡æˆ–ä¸­æ­¢æ ‡å¿—ï¼Œåœæ­¢æ‰§è¡Œ")
            return state
        if state['current_step'] >= len(state['plan']):
            log.success(f"âœ… æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ")
            return state
        
        state['execution_rounds'] += 1
        step = state['plan'][state['current_step']]
        hints = state.get('hints_by_step', {}).get(state['current_step'])
        
        log.info(f"ğŸ“ å½“å‰æ­¥éª¤ {state['current_step'] + 1}/{len(state['plan'])}: {step.get('desc', step)[:80]}...")
        
        # é€‰æ‹©å¹¶è°ƒç”¨ä¸‹ä¸€å·¥å…·
        tool_name, tool_input = self.choose_next_tool(step, state['step_tool_results'], hints)
        log.info(f"ğŸ”¨ è°ƒç”¨å·¥å…·: {tool_name}")
        log.debug(f"   å·¥å…·è¾“å…¥: {str(tool_input)[:200]}...")
        
        outcome = self.run_tool_for_step(tool_name, tool_input)
        log.info(f"ğŸ“¤ å·¥å…·æ‰§è¡Œå®Œæˆ")
        log.debug(f"   å·¥å…·è¾“å‡º: {str(outcome.get('output', ''))[:200]}...")
        
        state['step_tool_calls'] += 1
        state['step_tool_results'].append(outcome)
        
        # æ— è¿›å±•æ£€æµ‹ï¼ˆç›¸ä¼¼åº¦/ä¿¡æ¯å¢é‡ï¼‰
        outs = [r.get("output", "") for r in state['step_tool_results'] if isinstance(r.get("output", ""), str)]
        if self.info_gain_ok(outs):
            state['no_progress_streak'] = 0
            log.debug(f"âœ… ä¿¡æ¯å¢é‡æ­£å¸¸")
        else:
            state['no_progress_streak'] += 1
            log.warning(f"âš ï¸ æ£€æµ‹åˆ°æ— è¿›å±•ï¼Œè¿ç»­æ¬¡æ•°: {state['no_progress_streak']}")
        
        # å®Œæˆåˆ¤æ®
        log.info(f"ğŸ” æ£€æŸ¥æ­¥éª¤æ˜¯å¦å®Œæˆ (å·²è°ƒç”¨å·¥å…· {state['step_tool_calls']} æ¬¡)...")
        if self.is_step_complete(step, state['step_tool_results']):
            log.success(f"âœ… æ­¥éª¤ {state['current_step'] + 1} å®Œæˆï¼")
            state['results'].append({
                "step": step['desc'],
                "evidence": [r.get("output") for r in state['step_tool_results']]
            })
            state['current_step'] += 1
            state['step_tool_calls'] = 0
            state['step_tool_results'] = []
            state['no_progress_streak'] = 0
            log.info(f"â¡ï¸ è¿›å…¥ä¸‹ä¸€æ­¥éª¤")
            return state
        
        # æœªå®Œæˆï¼šæ˜¯å¦éœ€è¦äº¤ç”±è·¯ç”±å†³å®š SelfCheck / StrategyShift / ç»§ç»­
        log.info(f"â­ï¸ æ­¥éª¤æœªå®Œæˆï¼Œç»§ç»­æ‰§è¡Œæˆ–ç­‰å¾…åæ€")
        return state
    
    def choose_next_tool(self, step: dict,
                         partial_results: List[Dict[str, Any]],
                         hints: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict[str, Any]]:
        """é€‰æ‹©ä¸‹ä¸€ä¸ªå·¥å…·åŠå…¶å‚æ•°"""
        hints = hints or {}
        if hints.get("tool_override"):
            return hints["tool_override"], hints.get("params_patch", {})
        
        if "æ£€ç´¢" in step['desc']:
            base = {"q": hints.get("query_patch", "example query"), "k": hints.get("k", 5)}
            return hints.get("prefer_tool", "web_search"), base
        if "å½’çº³" in step['desc']:
            chunks = [r.get("output", "") for r in partial_results]
            return hints.get("prefer_tool", "rag_summarize"), {"chunks": chunks}
        return hints.get("prefer_tool", "writer"), {
            "draft": "\n".join([r.get("output", "") for r in partial_results])
        }
    
    def run_tool_for_step(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¿è¡Œå·¥å…·ï¼ˆå ä½ç¬¦å®ç°ï¼Œéœ€è¦å­ç±»åŒ–æˆ–æ³¨å…¥çœŸå®å·¥å…·ï¼‰
        
        Args:
            tool_name: å·¥å…·åç§°
            tool_input: å·¥å…·è¾“å…¥å‚æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        # TODO: æ›¿æ¢ä¸ºä½ çš„çœŸå®å·¥å…·è°ƒç”¨ï¼ˆæ£€ç´¢/çˆ¬è™«/RAG/ä»£ç /æµè§ˆå™¨/DeepResearch ç­‰ï¼‰
        if tool_name == "web_search":
            return {"tool": tool_name, "input": tool_input,
                    "output": "æœç´¢ç»“æœç‰‡æ®µA; ç‰‡æ®µB; ç‰‡æ®µC", "final": False}
        if tool_name == "rag_summarize":
            return {"tool": tool_name, "input": tool_input,
                    "output": "å½’çº³è¦ç‚¹ï¼š1) â€¦ 2) â€¦ 3) â€¦", "final": False}
        if tool_name == "writer":
            return {"tool": tool_name, "input": tool_input,
                    "output": "å¯äº¤ä»˜æ€»ç»“è‰ç¨¿ï¼ˆå«ç»“è®ºä¸å¼•ç”¨ï¼‰ã€‚", "final": True}
        return {"tool": tool_name, "input": tool_input, "output": "å ä½è¾“å‡º", "final": False}
    
    def info_gain_ok(self, outputs: List[str]) -> bool:
        """æ£€æµ‹ä¿¡æ¯å¢é‡æ˜¯å¦è¶³å¤Ÿ"""
        if len(outputs) < 2:
            return True
        return self._similarity(outputs[-1], outputs[-2]) < self.similarity_threshold
    
    def _similarity(self, a: str, b: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦"""
        sa, sb = set(a.split()), set(b.split())
        return 0.0 if not sa or not sb else len(sa & sb) / len(sa | sb)
    
    def is_step_complete(self, step: dict, partial_results: List[Dict[str, Any]]) -> bool:
        """åˆ¤æ–­æ­¥éª¤æ˜¯å¦å®Œæˆ"""
        if not partial_results:
            return False
        # å·¥å…·è‡ªå£°æ˜ final=True
        if partial_results[-1].get("final", False):
            return True
        # è‡³å°‘ N æ¬¡è°ƒç”¨ï¼Œé¿å…"ä¸€æ¬¡å³è¯¯åˆ¤å®Œæˆ"
        if len(partial_results) < self.min_calls_before_complete:
            return False
        
        # LLM è¯„å®¡ï¼šæ ¹æ® acceptance æ ‡å‡†å’Œè¯æ®åˆ¤æ–­æ˜¯å¦å®Œæˆ
        if self.llm_client and step.get('acceptance'):
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è¯„å®¡ä¸“å®¶ã€‚æ ¹æ®æ­¥éª¤çš„å®Œæˆæ ‡å‡†å’Œå·²æ”¶é›†çš„è¯æ®ï¼Œåˆ¤æ–­æ­¥éª¤æ˜¯å¦å·²å®Œæˆã€‚
åªè¿”å› "COMPLETE" æˆ– "INCOMPLETE"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""
            
            evidence_str = "\n".join([f"- {r.get('output', '')[:200]}" for r in partial_results])
            user_prompt = f"""æ­¥éª¤æè¿°ï¼š{step['desc']}
å®Œæˆæ ‡å‡†ï¼š{step['acceptance']}
å·²æ”¶é›†è¯æ®ï¼š
{evidence_str}

è¯·åˆ¤æ–­è¯¥æ­¥éª¤æ˜¯å¦å·²å®Œæˆï¼š"""
            
            response = self._call_llm(system_prompt, user_prompt, temperature=0.0)
            if "COMPLETE" in response.upper():
                return True
        
        # é»˜è®¤ï¼šè¾¾åˆ°æœ€å°è°ƒç”¨æ¬¡æ•°åè®¤ä¸ºå®Œæˆ
        return True
    
    def _call_llm(self, system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:
        """è°ƒç”¨ LLM å¹¶è¿”å›å“åº”æ–‡æœ¬"""
        if not self.llm_client:
            return f"[æ¨¡æ‹Ÿå“åº”: {user_prompt[:50]}...]"
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm_client.llm.invoke(messages)
            return response.content
        except Exception as e:
            print(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return f"[LLMè°ƒç”¨å¤±è´¥: {str(e)}]"

